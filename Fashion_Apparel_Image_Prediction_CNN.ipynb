{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, ZeroPadding2D, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/DataScienceClass/MINST_Digits_Identification/Images/train/'\n",
    "train_images=[]\n",
    "train_files=[]\n",
    "for filename in glob.glob(path + '*.png'): #assuming gif \n",
    "    # the next line opens the image and convert it to grey scale\n",
    "    im=Image.open(filename).convert('L')\n",
    "    # the next line, Image.getdata returns the pixel values as sequence of flatten values\n",
    "    data = im.getdata()\n",
    "    nparray = np.array(data,'uint8')\n",
    "    # print(nparray)\n",
    "    train_images.append([nparray,os.path.basename(filename)])\n",
    "#    train_files.append(os.path.basename(filename))\n",
    "    im.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/'\n",
    "train_images=[]\n",
    "train_files=[]\n",
    "for filename in glob.glob(path + '*.png'): #assuming gif \n",
    "    # the next line opens the image and convert it to grey scale\n",
    "    #im=Image.open(filename).convert('L')\n",
    "    # the next line, Image.getdata returns the pixel values as sequence of flatten values\n",
    "    #data = im.getdata()\n",
    "    #data = im.\n",
    "    #nparray = np.array(data,'uint8')\n",
    "    nparray = image.img_to_array(image.load_img(filename))\n",
    "    #print(nparray.shape)\n",
    "    train_images.append(nparray) #,os.path.basename(filename)])\n",
    "#    train_files.append(os.path.basename(filename))\n",
    "    im.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/'\n",
    "train_images=[]\n",
    "train_files=[]\n",
    "for filename in glob.glob(path + '*.png'):\n",
    "    nparray = image.img_to_array(image.load_img(filename))\n",
    "    train_images.append(nparray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/test_ScVgIM0/test/'\n",
    "test_images=[]\n",
    "test_files=[]\n",
    "for filename in glob.glob(path + '*.png'):\n",
    "    nparray = image.img_to_array(image.load_img(filename))\n",
    "    test_images.append(nparray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images).shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [7., 7., 7.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [9., 9., 9.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [3., 3., 3.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/test_ScVgIM0/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x1A8F26893D0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/24280.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24279</th>\n",
       "      <td>24280</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "24279  24280      9"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.id==24280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACmUlEQVR4nO2TTUvrShjH5+WZTDtNsEFsm7SxVN0pouBGydIXRHBVcC0i+Am6cufn6MK9iB9BEPEbCFJcWQRpwbTVJG0mM3cR6L1c7j3nLA+H/pbDM//nv/g9CM2Y8cfSarX+850QgjH+1RSMMSEEIWTbdrvd7vf7vu//cwAApnHkVxIJIVprpdTOzs7Z2VkYhi8vL5eXl/v7+9MZKaXWemVlBQB+UjUrmKYpAKyvr5+fn7uuOxwOl5eXy+XywsJCt9vtdDo3NzcPDw9CiHa7vb29/b+hAMAYi6IIITQ3N9doNHzf55w3m03TNCmlAKCUKhQK+Xw++5IkSRAEW1tbMG1EKZ1WG4/HUkopJULo6urKcZz7+/tisXh0dEQICcOQUmrbdjYZx7FhGFLKOI4ty9rd3cUZSql/NS2VShcXF3t7e7e3t9Vq1XVd13UfHx+bzWYulxsMBuPxGCFkWZYQotfrMcZs2zYMYzgcgtZaa40QEkIsLi46jrO2tnZ4eGhZ1t3d3enp6cHBwebmZhiGcRwTQp6ennzfZ4xRSqMo6vV6Hx8ftm2vrq4mScI555xjwzBarVaj0fj+/lZKJUkSRdHr6+v19XW9Xj8+Pv78/PQ8b2NjQynlui7nHGMMAAghSuloNArDcGlpSQjBOZ+fn+90Orher5+cnAghpssnk4nWulKpeJ7X7XYJIZ7n1Wo10zQdxzFNczAYfH19aa0ZY1n0dFOaps/Pzzifz5fL5VwuVywWS6VStVqtVCqFQgEAtNYAUKvVOOdRFEkpgyBI03Q0GjHGlFKZ7YyxIAje3t6CIOj3++/v738rBQCUUsuyKKWZCaZpSikJIZkGUkqlFCEkkyk7sIw4jjHGjDEp5WQy+bH7M2b8HvwFaygWSXrki3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x1A8F2689A30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/27454.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27453</th>\n",
       "      <td>27454</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "27453  27454      7"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.id==27454]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 28, 28, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size =(3,3),activation='relu',input_shape=(28,28,3)))\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 4.9754 - accuracy: 0.0980 - val_loss: 2.3029 - val_accuracy: 0.1001\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3038 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 61s 40ms/step - loss: 2.3028 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3030 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.1002\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3030 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.1002\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 62s 41ms/step - loss: 2.3054 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0987\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 63s 42ms/step - loss: 2.3026 - accuracy: 0.1033 - val_loss: 2.3026 - val_accuracy: 0.1004\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 63s 42ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1004\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 62s 41ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1009\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a8f4990c40>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10,validation_data =(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'SGD',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 58s 38ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 62s 42ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 61s 40ms/step - loss: 2.3027 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3027 - accuracy: 0.1022 - val_loss: 2.3026 - val_accuracy: 0.0966\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0966\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.0966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a88cf53d60>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 10,validation_data =(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Train Image to GreyScale i.e Black and White Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 60000/60000 [00:20<00:00, 2929.57it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/'\n",
    "train_image=[]\n",
    "train_file=[]\n",
    "for i in tqdm(range(train.shape[0])): \n",
    "    img = image.load_img('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/train_LbELtWX/train/'+train['id'][i].astype('str')+'.png', target_size=(28,28,1), grayscale=True)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X1=np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=train['label'].values\n",
    "y1 = to_categorical(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train,X1_test,y1_train,y1_test = train_test_split(X1,y1,random_state=42,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 10)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 28, 28, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "model_1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(128, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 57s 37ms/step - loss: 0.6696 - accuracy: 0.7625 - val_loss: 0.3076 - val_accuracy: 0.8874\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.3414 - accuracy: 0.8757 - val_loss: 0.2596 - val_accuracy: 0.9021\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.2826 - accuracy: 0.8963 - val_loss: 0.2357 - val_accuracy: 0.9124\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.2485 - accuracy: 0.9083 - val_loss: 0.2360 - val_accuracy: 0.9115\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.2192 - accuracy: 0.9177 - val_loss: 0.2255 - val_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.2028 - accuracy: 0.9257 - val_loss: 0.2243 - val_accuracy: 0.9193\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 61s 41ms/step - loss: 0.1794 - accuracy: 0.9339 - val_loss: 0.2189 - val_accuracy: 0.9228\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.1718 - accuracy: 0.9337 - val_loss: 0.2234 - val_accuracy: 0.9222\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.1565 - accuracy: 0.9402 - val_loss: 0.2241 - val_accuracy: 0.9229\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 61s 40ms/step - loss: 0.1485 - accuracy: 0.9431 - val_loss: 0.2117 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a89cb5ba60>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X1_train, y1_train, epochs=10, validation_data=(X1_test, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Test Images to GreyScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]C:\\Users\\dell\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1741.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_image = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    img = image.load_img('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/test_ScVgIM0/test/'+test['id'][i].astype('str')+'.png', target_size=(28,28,1), grayscale=True)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    test_image.append(img)\n",
    "test = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 is a greyscale image and is of the shape(n,28,28,1), model is of shape (n,28,28,3) which is a rgb image\n",
    "prediction = model_1.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('C:/Users/dell/Documents/AI-ML(Data Science Program)/Deep Learning for DataScience(started from 20-FEB-2021)/sample_submission_I5njJSF.csv')\n",
    "sample['label'] = prediction\n",
    "sample.to_csv('sample_cnn.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
